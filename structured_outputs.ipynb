{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bea3937",
   "metadata": {},
   "source": [
    "# Strucutred LLM Outputs\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "The project explores the use and benefits of structured LLM outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0d981",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96367f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "from typing import Any, Dict, List, Sequence, Union\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09512783",
   "metadata": {},
   "source": [
    "## Initialize Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e394ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef81b0b5",
   "metadata": {},
   "source": [
    "## Build MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e587f",
   "metadata": {},
   "source": [
    "The following code implements an interactive chatbot that connects to Claude, lets the model decide when to call Python tools (like searching arXiv or extracting paper info), executes those tools, and feeds the results back into the conversation â€” until the assistant provides a final, user-facing answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719a9cb",
   "metadata": {},
   "source": [
    "### Chatbot Code\n",
    "\n",
    "The chabot handles queries on a case by case basis. No memory is persistent across queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ac137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "client = anthropic.Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b963d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str) -> None:\n",
    "    \"\"\"\n",
    "    Process a single user query by interacting with the Anthropic LLM\n",
    "    and handling any tool calls requested by the model.\n",
    "\n",
    "    This function sends the query to Claude, monitors the response, and:\n",
    "      - Prints assistant text outputs directly.\n",
    "      - Executes tool calls if the model requests one.\n",
    "      - Passes tool results back to the model for further processing.\n",
    "      - Loops until the model produces a final text-only response.\n",
    "\n",
    "    Args:\n",
    "        query (str): The natural language input from the user.\n",
    "\n",
    "    Side Effects:\n",
    "        - Prints assistant replies and tool calls to stdout.\n",
    "    \"\"\"\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "\n",
    "    response = client.messages.create(\n",
    "        max_tokens=2024,\n",
    "        model='claude-3-7-sonnet-20250219',\n",
    "        tools=tools,       # assumes `tools` is defined globally\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    active = True\n",
    "    while active:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response.content:\n",
    "            # Case A: Assistant replies with plain text\n",
    "            if content.type == 'text':\n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "\n",
    "                if len(response.content) == 1:\n",
    "                    active = False\n",
    "\n",
    "            # Case B: Assistant requests a tool\n",
    "            elif content.type == 'tool_use':\n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "\n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "\n",
    "                # Execute tool and add result back into conversation\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_id,\n",
    "                            \"content\": result\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "                # Ask model for next step using tool result\n",
    "                response = client.messages.create(\n",
    "                    max_tokens=2024,\n",
    "                    model='claude-3-7-sonnet-20250219',\n",
    "                    tools=tools,\n",
    "                    messages=messages\n",
    "                )\n",
    "\n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    active = False\n",
    "\n",
    "\n",
    "def chat_loop() -> None:\n",
    "    \"\"\"\n",
    "    Start an interactive terminal chat loop with the chatbot.\n",
    "\n",
    "    Users can type queries, which are passed to `process_query` for handling.\n",
    "    Typing 'quit' ends the session.\n",
    "\n",
    "    Side Effects:\n",
    "        - Continuously prompts for user input.\n",
    "        - Prints assistant replies and tool call logs.\n",
    "    \"\"\"\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "\n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bebd8",
   "metadata": {},
   "source": [
    "## Build MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f77c1f",
   "metadata": {},
   "source": [
    "The following code takes the functions `process_query` and `chat_loop` and wraps them in a MCP_Chatbot class. This enables the chatbot to communicate with the MCP server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aec203",
   "metadata": {},
   "source": [
    "The MCP Client library brings in the following classes:\n",
    "\n",
    "* **`ClientSession`:** manages the connection and sends requests.\n",
    "\n",
    "* **`StdioServerParameters`:** defines how to launch the server.\n",
    "\n",
    "* **`stdio_client`:** helper to create a stdio transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca95fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".arxivvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
